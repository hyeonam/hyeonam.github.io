<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Hye Yeon Nam</title>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<style type="text/css">
<!--
@import url("../styles.css");
.style1 {font-weight: bold}
a:link {
	text-decoration: underline;
}
a:visited {
	text-decoration: underline;
}
a:hover {
	text-decoration: underline;
}
a:active {
	text-decoration: underline;
}
-->
</style>
</head>

<body id="white">

  <h1>Hye Yeon Nam </h1>
  <div id="mainnav">
<ul>
<li><a href="../index.html">Project</a> : </li>
<li><a href="pap/pap.html">Paper </a> : </li>
<li><a href="res.htm">Resume</a> : </li>
<li> </li>
<li><a href="cont.htm">About</a></li>
<li></li></ul>
</div>
<h2 class="style1">Tongue Music</h2>
<p>2009 Jan, Experimental Instrument, Collaboration with Ramaldo Martin<br />
<br />
Detailed Picture<strong></strong><br />
  <strong><em><img src="ton1.jpg" width="394" height="285" /> <img src="ton3.jpg" width="287" height="287" /></em></strong><br />
Documentation<br />
<object classid="clsid:02BF25D5-8C17-4B23-BC80-D3488ABDDC6B" width="320" height="254" codebase="http://www.apple.com/qtactivex/qtplugin.cab">
      <param name="SRC" value="ton.mov" />
      <param name="cache" value="true" />
      <param name="kioskmode" value="true" />
      <param name="autoplay" value="true" />
      <param name="controller" value="true" />
      <embed src="ton.mov" width="320" height="254" cache="true" kioskmode="true" controller="true" autoplay="true" bgcolor="black" pluginspage="http://www.quicktime.apple.com"></embed>
      </object>
<br />
<br />
<img src="ton4.jpg" width="674" height="454" />
<p>The Tongue Music system consists of two components: a bio-computer interface and an audio/video production system. <br />
The first component is a Tongue-Computer Interface (TCI), known as the Tongue Drive System (TDS).&nbsp; The headset possesses sensors that detect magnetic flux emanating from a small magnet secured on the tongue with tissue adhesive.&nbsp; These sensor readings are wirelessly transmitted to the computer.&nbsp; A signal processing algorithm converts the readings into mouse commands that are then employed by the audio/video production system.<br />
The A/V system, designed in Max/MSP, uses the tongue-driven input for audio and video synthesis. In the case of the latter, the system utilizes the mouse position to non-linearly control the visual playback. &nbsp;By also mapping the mouse position to 128 distinct notes, the user can continuously - or occasionally - play music with the tongue or even add in extra background beats.&nbsp; Currently, there are three distinct quadruple-time background beats, which the user can change to that of a piano, bell, electric guitar or pipe organ.
<p><strong>Credit</strong><br />
  Hye Yeon Nam:Experimental Instrument Concept and A/V design<br />
Ramaldo Martin: Tongue-Computer Interface (TCI)<br />
GT-Bionics Laboratory<br />
GT-LCC/Digital Media
<p><br />
</body>
</html>